{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f771b45",
   "metadata": {},
   "source": [
    "# Termin 2 - Machine Learning Algorithmen (Aufgabe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7539998-4c11-4853-a763-468c4bee0142",
   "metadata": {},
   "source": [
    "## Einführung in das Maschinelle Lernen  \n",
    "### Überblick: Überwachtes vs. Unüberwachtes Lernen\n",
    "\n",
    "Maschinelles Lernen ist ein Teilbereich der künstlichen Intelligenz. Dabei lernt ein Modell aus vorhandenen Daten, um Vorhersagen oder Entscheidungen zu treffen – ohne explizit programmiert zu werden.\n",
    "\n",
    "---\n",
    "\n",
    "### Überwachtes Lernen (Supervised Learning)\n",
    "\n",
    "Beim überwachten Lernen wird ein Modell mit **gelabelten Trainingsdaten** trainiert. Das bedeutet: Die Daten enthalten sowohl Eingabewerte als auch Zielwerte (Labels), anhand derer das Modell lernt.\n",
    "\n",
    "#### Typische Aufgaben:\n",
    "\n",
    "- **Klassifikation**  \n",
    "  Vorhersage einer Kategorie, z. B.:\n",
    "  - Binär: Ja/Nein, Krank/Gesund\n",
    "  - Mehrklassen: Hund, Katze, Vogel\n",
    "\n",
    "- **Regression**  \n",
    "  Vorhersage eines kontinuierlichen Werts, z. B.:  \n",
    "  Grundwasserstand in Abhängigkeit von Niederschlag und Landnutzung\n",
    "\n",
    "#### Häufig verwendete Algorithmen:\n",
    "\n",
    "- Logistische Regression  \n",
    "- Entscheidungsbäume (Decision Trees)  \n",
    "- Random Forest  \n",
    "- Support Vector Machines (SVM)\n",
    "\n",
    "---\n",
    "\n",
    "### Unüberwachtes Lernen (Unsupervised Learning)\n",
    "\n",
    "Hier gibt es **keine Zielwerte**. Das Modell versucht eigenständig, Muster oder Strukturen in den Daten zu erkennen.\n",
    "\n",
    "#### Typische Methoden:\n",
    "\n",
    "- K-Means-Clustering: Gruppiert ähnliche Datenpunkte  \n",
    "- Principal Component Analysis (PCA): Reduziert die Anzahl der Merkmale (Dimensionsreduktion)\n",
    "\n",
    "---\n",
    "\n",
    "Weitere Informationen zu den in `scikit-learn` verfügbaren Algorithmen für überwachtes Lernen findet ihr unter:  \n",
    "https://scikit-learn.org/stable/supervised_learning.html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdbc56e4",
   "metadata": {},
   "source": [
    "# Teil 1 – Überwachtes Lernen\n",
    "\n",
    "### Binäre Klassifikation\n",
    "\n",
    "Bei der binären Klassifikation wird ein Modell darauf trainiert, zwischen genau **zwei Klassen** zu unterscheiden.  \n",
    "Beispiel: Vorhersage, ob ein Patient krank oder gesund ist (Ja/Nein).\n",
    "\n",
    "---\n",
    "\n",
    "### Datensatz: Einlesen und Vorbereitung\n",
    "\n",
    "- **Datenbasis**: Grundwasser-Stichtagsmessungen aus dem Jahr 2005  \n",
    "- **Zielvariable**: Landnutzung – Vorhersage, ob landwirtschaftlich genutzt (Ja/Nein)  \n",
    "- **Problemtyp**: Binäre Klassifikation basierend auf Umweltmessdaten\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b44f3cc5",
   "metadata": {},
   "source": [
    "### Vorbereitung: Wichtige Bibliotheken importieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f59d919",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Grundlagen ---\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# --- Datenvorverarbeitung ---\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# --- Klassifikationsmodelle ---\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# --- Bewertung des Modells ---\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "# --- Pipeline zur Modellierung ---\n",
    "from sklearn.pipeline import Pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e477481e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Einladen der Daten\n",
    "filename = 'gwdata_2005.csv'\n",
    "dataset = pd.read_csv(filename, delimiter=';', encoding=\"ISO-8859-1\")\n",
    "\n",
    "# Preprocessing (Bereinigen von NaN-Werten und Entfernen von nicht benötigten Spalten)\n",
    "dataset_cleaned = dataset.dropna(axis=0, how='any')\n",
    "data = dataset_cleaned.drop(['GWNum','Messstelle','Rechtswert', 'Hochwert', 'Aquifer','Aquifer2','landuse'], axis=1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20c06947-30ad-447e-bcf8-cf35b8885860",
   "metadata": {},
   "source": [
    "### Explorative Übersicht über den Datensatz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "217de704-59bb-442c-aa35-d7798b19a904",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Überblick über Struktur, Inhalte und Korrelationen\n",
    "print(\"Form des Datensatzes:\", data.shape)\n",
    "print(\"\\nDatentypen:\")\n",
    "print(data.dtypes)\n",
    "\n",
    "print(\"\\nStatistische Kennzahlen:\")\n",
    "print(data.describe())\n",
    "\n",
    "print(\"\\nEindeutige Werte pro Spalte:\")\n",
    "print(data.nunique())\n",
    "\n",
    "print(\"\\nFehlende Werte pro Spalte:\")\n",
    "print(data.isnull().sum())\n",
    "\n",
    "print(\"\\nKorrelationen (numerisch):\")\n",
    "print(data.corr(numeric_only=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c4a3d8d-16be-4d15-a003-100430b3b051",
   "metadata": {},
   "source": [
    "### Zielvariable: `landuse_num`\n",
    "\n",
    "Die Spalte `landuse_num` ist die Zielvariable für die Klassifikation. Sie kodiert landwirtschaftliche Nutzung binär:\n",
    "\n",
    "- `0`: keine Landwirtschaft (`no_agr`)\n",
    "- `1`: landwirtschaftlich genutzt (`agr`)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d08472",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Anzahl der Klassen in 'landuse_num':\")\n",
    "print(data['landuse_num'].value_counts().rename(index={0: 'Keine Landwirtschaft', 1: 'Landwirtschaft'}))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c67215fc",
   "metadata": {},
   "source": [
    "### Aufteilen in Trainings- und Testdaten\n",
    "\n",
    "Um die Modellleistung objektiv zu bewerten, wird der Datensatz in zwei Teile getrennt:\n",
    "\n",
    "- **Trainingsdaten**: zum Trainieren des Modells\n",
    "- **Testdaten**: zur Überprüfung der Generalisierungsfähigkeit\n",
    "\n",
    "Typisches Verhältnis: 80 % Training, 20 % Test (Standardwert).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c13f5d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zufalls-Seed für Reproduzierbarkeit\n",
    "random_state = 42\n",
    "\n",
    "# Eingabedaten (X) und Zielvariable (y)\n",
    "X = data.drop('landuse_num', axis=1)\n",
    "y = data['landuse_num']\n",
    "\n",
    "# Aufteilen in Trainings- und Testdaten (80/20)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=random_state, shuffle=True\n",
    ")\n",
    "\n",
    "# Formen der Datensätze anzeigen\n",
    "print(\"X_train:\", X_train.shape)\n",
    "print(\"X_test: \", X_test.shape)\n",
    "print(\"y_train:\", y_train.shape)\n",
    "print(\"y_test: \", y_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "726f9da9-d551-4799-b179-5f91c5ce1962",
   "metadata": {},
   "source": [
    "### Support Vector Machines (SVM)\n",
    "\n",
    "Support Vector Machines sind leistungsfähige Verfahren für Klassifikation und Regression.  \n",
    "Sie arbeiten, indem sie eine **Entscheidungsgrenze** (Hyperebene) im Merkmalsraum bestimmen, die die Klassen bestmöglich voneinander trennt.\n",
    "\n",
    "#### Support Vector Classification (SVC)\n",
    "\n",
    "`SVC` ist die SVM-Variante für Klassifikationsaufgaben. Sie eignet sich besonders für komplexe, auch nicht-linear trennbare Probleme – etwa durch den Einsatz von Kernfunktionen (Kernels).\n",
    "\n",
    "---\n",
    "\n",
    "Weitere Informationen in der scikit-learn-Dokumentation:\n",
    "\n",
    "- [SVM in scikit-learn](https://scikit-learn.org/stable/modules/svm.html)  \n",
    "- [Modellbewertung & Scoring](https://scikit-learn.org/stable/modules/model_evaluation.html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5be3026",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reproduzierbarkeit sicherstellen\n",
    "random_state = 88\n",
    "\n",
    "# Bewertungsmetrik für Cross-Validation\n",
    "scoring = 'accuracy'\n",
    "\n",
    "# Anzahl der Folds für K-Fold-Validierung\n",
    "n_splits = 10\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad7b544c",
   "metadata": {},
   "source": [
    "### 1/3: SVC mit unskalierten Eingabedaten\n",
    "\n",
    "In diesem Schritt wird ein `SVC`-Modell (Support Vector Classification) mit den unskalierten Eingabedaten trainiert.\n",
    "\n",
    "Support Vector Machines sind empfindlich gegenüber ungleich skalierten oder unterschiedlich verteilten Merkmalen.  \n",
    "Fehlende Standardisierung kann die Modellgüte deutlich beeinträchtigen. Dieses Modell dient daher als Referenz für spätere Vergleiche mit skalierten Varianten.\n",
    "\n",
    "[Mehr zur SVC in der scikit-learn-Dokumentation](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html#sklearn.svm.SVC)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69af2315",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM-Modell mit RBF-Kernel (ohne Skalierung)\n",
    "svm_raw = SVC(kernel='rbf', gamma='auto')\n",
    "\n",
    "# K-Fold-Setup\n",
    "kfold = KFold(n_splits=n_splits, random_state=random_state, shuffle=True)\n",
    "\n",
    "# Kreuzvalidierung\n",
    "cv_scores_svm_raw = cross_val_score(svm_raw, X_train, y_train, cv=kfold, scoring=scoring)\n",
    "\n",
    "# Mittelwert und Standardabweichung der Genauigkeit\n",
    "mean_accuracy_raw = cv_scores_svm_raw.mean()\n",
    "std_accuracy_raw = cv_scores_svm_raw.std()\n",
    "\n",
    "# Ergebnis ausgeben\n",
    "print(f\"SVM Accuracy (ohne Skalierung): {mean_accuracy_raw:.3f} ± {std_accuracy_raw:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b28d9083",
   "metadata": {},
   "source": [
    "### 2/3: SVC mit skalierten Eingabedaten\n",
    "\n",
    "Durch Standardisierung (z. B. mit `StandardScaler`) werden alle Merkmale auf denselben Wertebereich gebracht.  \n",
    "Dies kann die Leistung von SVMs erheblich verbessern.\n",
    "\n",
    "Im Folgenden wird dasselbe `SVC`-Modell wie zuvor verwendet, diesmal jedoch mit vorgeschalteter Skalierung der Eingabedaten.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d16910",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Erstellen und Anwenden des StandardScalers auf die Trainingsdaten\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "# SVM-Modell mit RBF-Kernel (auf skalierten Daten)\n",
    "svm_scaled = SVC(kernel='rbf', gamma='auto')\n",
    "\n",
    "# K-Fold-Cross-Validation definieren\n",
    "kfold = KFold(n_splits=n_splits, random_state=random_state, shuffle=True)\n",
    "\n",
    "# Kreuzvalidierung mit skalierten Daten\n",
    "cv_scores_svm_scaled = cross_val_score(svm_scaled, X_train_scaled, y_train, cv=kfold, scoring=scoring)\n",
    "\n",
    "# Genauigkeit und Streuung berechnen\n",
    "mean_accuracy_scaled = cv_scores_svm_scaled.mean()\n",
    "std_accuracy_scaled = cv_scores_svm_scaled.std()\n",
    "\n",
    "# Ausgabe\n",
    "print(f\"SVM Accuracy (mit Skalierung): {mean_accuracy_scaled:.3f} ± {std_accuracy_scaled:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a08ed19c",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#e6f0ff; padding:10px; border-radius:5px; font-weight:bold\">\n",
    "   For Your Interest: Pipeline mit mehreren Verarbeitungsschritten\n",
    "</div>\n",
    "\n",
    "\n",
    "\n",
    "Der folgende Abschnitt zeigt, wie man mithilfe von `Pipeline` mehrere Verarbeitungsschritte nahtlos kombiniert – von der Vorverarbeitung bis zur Modellierung mit einem SVM.\n",
    "\n",
    "**Typische Komponenten einer solchen Pipeline:**\n",
    "\n",
    "- **Imputation**:  \n",
    "  `SimpleImputer(strategy='mean')`  \n",
    "  → Ersetzt fehlende Werte durch den Mittelwert der jeweiligen Spalte.\n",
    "\n",
    "- **Skalierung**:  \n",
    "  `StandardScaler()`  \n",
    "  → Skaliert alle Merkmale auf dieselbe Größenordnung.\n",
    "\n",
    "- **Feature Engineering (optional)**:  \n",
    "  `PolynomialFeatures(degree=2)`  \n",
    "  → Fügt polynomiale Merkmale hinzu, um nichtlineare Zusammenhänge abzubilden.\n",
    "\n",
    "- **Feature Selection**:  \n",
    "  `SelectKBest(f_classif, k=10)`  \n",
    "  → Wählt die 10 Merkmale mit der höchsten Relevanz anhand des ANOVA-F-Tests aus.\n",
    "\n",
    "- **Dimensionsreduktion**:  \n",
    "  `PCA(n_components=0.95)`  \n",
    "  → Reduziert die Dimension, wobei 95 % der Varianz erhalten bleiben.\n",
    "\n",
    "- **Klassifikator**:  \n",
    "  `SVC(kernel='rbf', gamma='auto')`  \n",
    "  → SVM mit RBF-Kernel für die Klassifikation.\n",
    "\n",
    "---\n",
    "\n",
    "> **Hinweis:**  \n",
    "> Der folgende Code dient der Veranschaulichung.  \n",
    "> Einige der verwendeten Komponenten sind möglicherweise **nicht in der aktuellen Umgebung installiert** und daher **nicht direkt ausführbar**.\n",
    "```\n",
    "pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('poly', PolynomialFeatures(degree=2)),\n",
    "    ('feature_select', SelectKBest(f_classif, k=10)),\n",
    "    ('pca', PCA(n_components=0.95)),\n",
    "    ('svm', SVC(kernel='rbf', gamma='auto'))\n",
    "])\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be77ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline: Skalierung + SVM-Modell\n",
    "svm_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('svm', SVC(kernel='rbf', gamma='auto'))\n",
    "])\n",
    "\n",
    "# K-Fold-Cross-Validation definieren\n",
    "kfold = KFold(n_splits=n_splits, random_state=random_state, shuffle=True)\n",
    "\n",
    "# Kreuzvalidierung mit der Pipeline\n",
    "cv_scores_svm_pipeline = cross_val_score(svm_pipeline, X_train, y_train, cv=kfold, scoring=scoring)\n",
    "\n",
    "# Genauigkeit berechnen\n",
    "mean_accuracy_pipeline = cv_scores_svm_pipeline.mean()\n",
    "std_accuracy_pipeline = cv_scores_svm_pipeline.std()\n",
    "\n",
    "# Ausgabe der mittleren Genauigkeit ± Standardabweichung\n",
    "print(f\"SVM Accuracy (Pipeline): {mean_accuracy_pipeline:.3f} ± {std_accuracy_pipeline:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41499c27",
   "metadata": {},
   "source": [
    "### 3/3: Random Forest Classifier\n",
    "\n",
    "Der `RandomForestClassifier` ist ein Ensemble-Lernverfahren, das auf einer Vielzahl von Entscheidungsbäumen basiert.  \n",
    "Durch das sogenannte Bagging (Bootstrap Aggregation) und die zufällige Auswahl von Features bei jedem Split werden Überanpassung reduziert und die Generalisierungsfähigkeit erhöht.\n",
    "\n",
    "Vorteile:\n",
    "- Robust gegenüber Ausreißern und Rauschen\n",
    "- Kaum anfällig für Overfitting bei ausreichender Baumanzahl\n",
    "- Gut skalierbar und vielseitig einsetzbar (Klassifikation und Regression)\n",
    "\n",
    "[Weitere Informationen zum `RandomForestClassifier` in scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad6ef73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest-Modell mit Standardparametern\n",
    "rf = RandomForestClassifier(random_state=random_state)\n",
    "\n",
    "# K-Fold-Cross-Validation definieren\n",
    "kfold = KFold(n_splits=n_splits, random_state=random_state, shuffle=True)\n",
    "\n",
    "# Kreuzvalidierung mit skalierten Eingabedaten\n",
    "cv_scores_rf = cross_val_score(rf, X_train_scaled, y_train, cv=kfold, scoring=scoring)\n",
    "\n",
    "# Genauigkeit und Standardabweichung berechnen\n",
    "mean_accuracy_rf = cv_scores_rf.mean()\n",
    "std_accuracy_rf = cv_scores_rf.std()\n",
    "\n",
    "# Ausgabe\n",
    "print(f\"Random Forest Accuracy: {mean_accuracy_rf:.3f} ± {std_accuracy_rf:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c30cc7e",
   "metadata": {},
   "source": [
    "### Vergleich der Ergebnisse\n",
    "\n",
    "Im Folgenden werden die mittleren Genauigkeiten der drei Modelle gegenübergestellt:\n",
    "\n",
    "- **SVC ohne Skalierung**\n",
    "- **SVC mit Skalierung**\n",
    "- **Random Forest Classifier**\n",
    "\n",
    "Der Vergleich dient zur Veranschaulichung der Auswirkungen von Vorverarbeitung und Modellwahl auf die Klassifikationsgenauigkeit.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "443e662b-fd56-41b1-8d72-b4a46e746fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ergebnisse aus Cross-Validation (Accuracy-Werte pro Fold)\n",
    "results = [\n",
    "    cv_scores_svm_raw,        # SVM Unskaliert\n",
    "    cv_scores_svm_scaled,      # SVM mit manueller Skalierung   \n",
    "    cv_scores_rf,             # Random Forest\n",
    "]\n",
    "\n",
    "# Boxplot zum Vergleich der Modelle\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.boxplot(results, patch_artist=True)\n",
    "plt.title('Vergleich der Modelle (Kreuzvalidierung)')\n",
    "plt.xticks([1, 2, 3], ['SVM', 'SVM (scaled)', 'Random Forest'])\n",
    "plt.ylabel('Accuracy')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33e58bd1-4d7f-4823-8966-90991f16e0a9",
   "metadata": {},
   "source": [
    "### Auswertung des besten Modells\n",
    "\n",
    "Nach dem Vergleich der Modelle anhand ihrer Kreuzvalidierungsergebnisse wird in diesem Abschnitt das Modell mit der höchsten mittleren Genauigkeit näher ausgewertet.\n",
    "\n",
    "Die folgenden Analyseschritte können dabei durchgeführt werden:\n",
    "\n",
    "- Training des Modells auf dem vollständigen Trainingsdatensatz\n",
    "- Vorhersage auf dem Testdatensatz (`X_test`)\n",
    "- Berechnung relevanter Metriken:\n",
    "  - Konfusionsmatrix\n",
    "  - Genauigkeit, Präzision, Recall, F1-Score\n",
    "- Optional: Visualisierung der Konfusionsmatrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe49df5-75ad-48da-a760-917ec418eebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modell für finale Auswertung auf dem Testdatensatz\n",
    "rf_final = RandomForestClassifier(random_state=random_state)\n",
    "\n",
    "# Skalierung der Testdaten mit dem bereits auf Trainingsdaten gefitteten Scaler\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Training des Random Forest auf dem gesamten (skalierten) Trainingsdatensatz\n",
    "rf_final.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Vorhersage auf dem (skalierten) Testdatensatz\n",
    "y_pred = rf_final.predict(X_test_scaled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c7f75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Genauigkeit auf dem Testdatensatz berechnen\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "# Konfusionsmatrix berechnen\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "# Klassifikationsbericht mit Precision, Recall, F1-Score\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "print(\"Classification Report:\")\n",
    "print(class_report)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8609941d-52ec-4ca8-a359-d94a5538ad10",
   "metadata": {},
   "source": [
    "**Ergebnis:**  \n",
    "Das Modell erkennt Klasse 0 (*keine Landwirtschaft*) sehr gut (**Recall: 89 %**).  \n",
    "Bei Klasse 1 (*Landwirtschaft*) gibt es größere Probleme:  \n",
    "Die **Precision** (Wie zuverlässig ist das Modell, wenn es „1“ sagt) ist gut,  \n",
    "der **Recall** (Wie viele echte „1“ wurden erkannt) jedoch nur mittelmäßig.  \n",
    "Der **F1-Score** (Kompromiss zwischen beiden) liegt entsprechend im mittleren Bereich.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef27a887-df3b-4d94-9405-aa771a4aa4ae",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Multiklassen-Klassifikation\n",
    "Viele reale Klassifikationsprobleme bestehen nicht nur aus zwei, sondern aus mehreren Klassen.  \n",
    "Multiklassen-Klassifikation bezeichnet die Vorhersage einer von mehr als zwei möglichen Zielklassen.\n",
    "#### IRIS-Datensatz laden\n",
    "\n",
    "Der Iris-Datensatz enthält 150 Beispiele von Blumen, die jeweils einer von drei Arten angehören (*Setosa*, *Versicolor* oder *Virginica*).  \n",
    "Er besteht aus vier numerischen Merkmalen: Länge und Breite von Kelchblatt (*Sepal*) und Kronblatt (*Petal*).\n",
    "\n",
    "Dieser Datensatz eignet sich gut, um verschiedene Machine-Learning-Modelle hinsichtlich ihrer Fähigkeit zur Klassifikation mehrerer Klassen zu testen.\n",
    "\n",
    "<div style=\"text-align:center\">\n",
    "  <img src=\"https://s3.amazonaws.com/assets.datacamp.com/blog_assets/Machine+Learning+R/iris-machinelearning.png\" width=\"75%\">\n",
    "</div>\n",
    "\n",
    "Der Datensatz wird als sogenanntes `Bunch`-Objekt geladen. Dieses enthält neben den Eingabedaten auch Zusatzinformationen wie z. B.:\n",
    "\n",
    "- **data**: Ein NumPy-Array mit den Merkmalswerten.\n",
    "- **target**: Ein NumPy-Array mit den Zielwerten (0, 1, 2).\n",
    "- **feature_names**: Namen der Merkmale (z. B. `sepal length`).\n",
    "- **target_names**: Namen der Zielklassen (`setosa`, `versicolor`, `virginica`).\n",
    "- **DESCR**: Beschreibung des Datensatzes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a184fd8-b460-46e7-a061-a783fa79fcc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "\n",
    "# Laden des Iris-Datensatzes\n",
    "iris = load_iris()\n",
    "\n",
    "# Extrahieren der Merkmale und des Targets aus dem Iris-Datensatz\n",
    "X = iris.data  # Merkmale\n",
    "y = iris.target  # Zielwerte\n",
    "#print(iris.DESCR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1667fee",
   "metadata": {},
   "source": [
    "## Aufgabe: Multiklassen-Klassifikation mit dem Iris-Datensatz\n",
    "\n",
    "Führe eine Multiklassen-Klassifikation mit dem Iris-Datensatz durch.  \n",
    "Implementiere mindestens zwei Modelle:\n",
    "\n",
    "- Ein Modell auf Basis von **Support Vector Machines (SVM)**  \n",
    "  (einmal **ohne Skalierung** und einmal **mit Skalierung**)\n",
    "- Ein Modell auf Basis von **Random Forest (RF)**\n",
    "\n",
    "### Vorgehensweise:\n",
    "- Teile die Daten in Trainings- und Testdatensätze auf\n",
    "- Identifiziere relevante Merkmale für die Klassifikation\n",
    "- Implementiere die beiden Modelle\n",
    "- Führe eine Evaluierung mit den Testdaten durch\n",
    "- Berechne die Genauigkeit der Vorhersagen\n",
    "- Vergleiche die Ergebnisse beider Modelle\n",
    "- Diskutiere, welches Modell besser geeignet ist\n",
    "\n",
    "---\n",
    "\n",
    "### Bearbeitungsübersicht\n",
    "\n",
    "- [x] Laden des Iris-Datensatzes  \n",
    "- [ ] Aufteilen der Daten in Trainings- und Testdatensätze  \n",
    "- [ ] Identifikation relevanter Merkmale  \n",
    "- [ ] Implementierung eines SVM-Modells (unskaliert & skaliert)  \n",
    "- [ ] Implementierung eines Random Forest-Modells  \n",
    "- [ ] Evaluierung und Berechnung der Genauigkeit  \n",
    "- [ ] Vergleich und Diskussion der Ergebnisse  \n",
    "\n",
    "---\n",
    "\n",
    "### Hinweis:\n",
    "Achte auf eine angemessene Datenvorverarbeitung, insbesondere die **Skalierung der Eingabedaten** für SVM.  \n",
    "Teste außerdem unterschiedliche Hyperparameter, um die Modellleistung zu optimieren.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8e2a7ee-e5e3-4be9-bf57-dbe428eeaad8",
   "metadata": {},
   "source": [
    "### 1. Daten aufteilen\n",
    "\n",
    "- Erstelle X_train, X_test, Y_train, Y_test.\n",
    "- Definiere tesize und den random seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad2755a-d68b-41bd-bdc2-39fd16bd7a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Aufteilen in Trainings- und Testdaten (80/30)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(\"Trainingsdaten:\", X_train.shape)\n",
    "print(\"Testdaten:\", X_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f11c1e8-b67c-4a67-8396-4ccb00bf6dfa",
   "metadata": {},
   "source": [
    "### 2. SVM-Modell (ohne Skalierung)\n",
    "- Erstelle Modell\n",
    "- Definiere K-Fold CV\n",
    "- Berechne und Speichere mittlere Genauigkeit und Standardabweichung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f8c3a3-bfea-42bf-88ad-c002ff6de9a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM ohne Skalierung\n",
    "svm_raw = SVC(kernel='rbf', gamma='scale')\n",
    "svm_raw.fit(X_train, y_train)\n",
    "y_pred_svm_raw = svm_raw.predict(X_test)\n",
    "\n",
    "# Auswertung\n",
    "acc_svm_raw = accuracy_score(y_test, y_pred_svm_raw)\n",
    "print(f\"SVM Accuracy (ohne Skalierung): {acc_svm_raw:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd464b4b-1b2e-4310-87d6-c583b98e9491",
   "metadata": {},
   "source": [
    "### 3. SVM-Modell (mit Skalierung)\n",
    "- Erstelle Modell\n",
    "- Definiere K-Fold CV\n",
    "- Berechne und Speichere mittlere Genauigkeit und Standardabweichung\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0257751-7e63-4648-8f42-fec6d32a718c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Skalierung\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# SVM mit Skalierung\n",
    "svm_scaled = SVC(kernel='rbf', gamma='scale')\n",
    "svm_scaled.fit(X_train_scaled, y_train)\n",
    "y_pred_svm_scaled = svm_scaled.predict(X_test_scaled)\n",
    "\n",
    "# Auswertung\n",
    "acc_svm_scaled = accuracy_score(y_test, y_pred_svm_scaled)\n",
    "print(f\"SVM Accuracy (mit Skalierung): {acc_svm_scaled:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3caaac4-58be-4ac7-b401-64da04d860c7",
   "metadata": {},
   "source": [
    "### 4. Random Forest-Modell\n",
    "- Erstelle Modell\n",
    "- Definiere K-Fold CV\n",
    "- Berechne und Speichere mittlere Genauigkeit und Standardabweichung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "215e836c-d9bd-4cf7-9366-47fbcc652d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest (braucht keine Skalierung)\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "\n",
    "# Auswertung\n",
    "acc_rf = accuracy_score(y_test, y_pred_rf)\n",
    "print(f\"Random Forest Accuracy: {acc_rf:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e51b2fbd-4530-4f36-9144-98993a653e7f",
   "metadata": {},
   "source": [
    "### 5. Vergleich der Modellgenauigkeiten\n",
    "\n",
    "- Führe Ergebnisse zusammen und Plotte sie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e38fb633-e063-4711-a2e0-2eec20fc1212",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Modellvergleich:\")\n",
    "print(f\"- SVM (ohne Skalierung):     {acc_svm_raw:.3f}\")\n",
    "print(f\"- SVM (mit Skalierung):      {acc_svm_scaled:.3f}\")\n",
    "print(f\"- Random Forest:             {acc_rf:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc21a16c-4d01-4c7d-8d14-34d647b83cd9",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Regression\n",
    "\n",
    "### Concrete-Datensatz\n",
    "\n",
    "Der Concrete-Datensatz enthält verschiedene Eigenschaften von Betonmischungen und deren resultierende Druckfestigkeit.  \n",
    "Er umfasst **1.030 Datensätze** mit **8 Eingabevariablen** und einer Zielgröße (Regression):\n",
    "\n",
    "**Eingabevariablen:**\n",
    "- Cement (*Zement*)\n",
    "- Blast Furnace Slag (*Hüttenzement*)\n",
    "- Fly Ash (*Flugasche*)\n",
    "- Water (*Wasser*)\n",
    "- Superplasticizer (*Fließmittel*)\n",
    "- Coarse Aggregate (*Grobgestein*)\n",
    "- Fine Aggregate (*Feingestein*)\n",
    "- Age (*Alter in Tagen*)\n",
    "\n",
    "**Zielvariable:**\n",
    "- Concrete Compressive Strength (*Druckfestigkeit des Betons*, in MPa)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f353cc4-f9e9-4d45-afee-558f6117c21b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concrete-Datensatz laden\n",
    "data = pd.read_csv('Concrete_Data.csv', sep=';', encoding='ISO-8859-1')\n",
    "\n",
    "# Vorschau auf die ersten 5 Zeilen\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dadf38c6-c3b2-4190-91d0-100cff3fdf43",
   "metadata": {},
   "source": [
    "### Hinweis zur Modellbewertung (Regression)\n",
    "\n",
    "Da wir nun eine **Regression** durchführen (nicht Klassifikation), verwenden wir eine andere Metrik zur Bewertung der Modellgüte: den **R²-Score**.\n",
    "\n",
    "Der R²-Score (Bestimmtheitsmaß) gibt an, wie gut die vorhergesagten Werte zu den tatsächlichen Werten passen.  \n",
    "Ein Wert von 1 bedeutet perfekte Vorhersage, 0 entspricht dem Mittelwertsmodell, negative Werte deuten auf schlechte Modellanpassung hin.\n",
    "\n",
    "Wir verwenden den `r2_score` aus `sklearn.metrics`.\n",
    "\n",
    "Weitere Informationen und alternative Regressionsmetriken wie MAE oder RMSE findest du unter:  \n",
    "[scikit-learn.org – Model Evaluation (Regression)](https://scikit-learn.org/stable/modules/model_evaluation.html#regression-metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c62be961-2efd-4051-a367-4910a7433432",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Einstellungen für Modellvergleich und Reproduzierbarkeit\n",
    "\n",
    "# Zufalls-Seed für Reproduzierbarkeit der Ergebnisse\n",
    "random_seed = 88\n",
    "\n",
    "# Bewertungsmetrik für Regressionsmodelle\n",
    "scoring_metric = 'r2'  # R² (Bestimmtheitsmaß)\n",
    "\n",
    "# Anzahl der Folds für K-Fold Cross-Validation\n",
    "num_folds = 10\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf19b685-4738-41f5-bf2a-46c9aa0e60c3",
   "metadata": {},
   "source": [
    "## Preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c84f5a4-ad33-4dbd-b32b-ec17bb147e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setzen des Seeds für die Reproduzierbarkeit\n",
    "random_state = 42\n",
    "\n",
    "# Aufteilen der Daten in Trainings- und Testdaten\n",
    "X = data.drop('Druckfestigkeit', axis=1)  # Spalte Zielvariable ab\n",
    "Y = data['Druckfestigkeit']  # Definiere 'landuse_num' als Zielvariable\n",
    "test_size = 0.2  # Anteil der Testdaten: 20%\n",
    "\n",
    "# Mischen und Aufteilen der Daten in Trainings- und Testdaten\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=test_size, random_state=random_state, shuffle=True)\n",
    "\n",
    "print(\"Form der Trainingsdaten (X_train):\", X_train.shape)\n",
    "print(\"Form der Testdaten (X_test):\", X_test.shape)\n",
    "print(\"Form der Trainingszielvariablen (Y_train):\", Y_train.shape)\n",
    "print(\"Form der Testzielvariablen (Y_test):\", Y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfa35317-ea7b-4291-b82b-2e9a2b7f800b",
   "metadata": {},
   "source": [
    "<span style=\"color: red; font-size: 24px\"><strong>Aufgabe:</strong></span>  \n",
    "Entwickle zwei verschiedene Modelle zur Vorhersage der **Druckfestigkeit** des Betons:  \n",
    "– eines basierend auf **Support Vector Machines (SVM)**  \n",
    "– eines basierend auf **Random Forest (RF)**\n",
    "\n",
    "### Schritte:\n",
    "- [x] **Daten aufteilen:** Teile die Daten in Trainings- und Testdatensätze auf  \n",
    "- [ ] **Modelle implementieren:** Implementiere ein SVM-Modell und ein Random Forest-Modell  \n",
    "- [ ] **Trainieren & evaluieren:** Trainiere die Modelle und evaluiere sie auf den Testdaten  \n",
    "- [ ] **Genauigkeit berechnen:** Ermittle die Vorhersagegüte (z. B. R² oder MAE)  \n",
    "- [ ] **Ergebnisse vergleichen:** Vergleiche beide Modelle und beurteile ihre Eignung\n",
    "\n",
    "---\n",
    "\n",
    "### Nützliche Links:\n",
    "\n",
    "- [Scikit-learn Übersicht](https://scikit-learn.org)  \n",
    "- [SVR – Support Vector Regression](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVR.html)  \n",
    "- [RandomForestRegressor](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html)  \n",
    "- [Model Evaluation in sklearn](https://scikit-learn.org/stable/modules/model_evaluation.html)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32b5fcbc-cc97-44ca-a8b3-364b6b58ce10",
   "metadata": {},
   "source": [
    "**<span style=\"font-size: 24px\">Support Vector Regressor</span>**\n",
    "\n",
    "**<span style=\"font-size: 18px\">Support Vector Regressor (ohne skalierung)</span>**\n",
    "\n",
    "- Erstelle Modell\n",
    "- Definiere K-Fold CV\n",
    "- Berechne und Speichere mittlere Genauigkeit und Standardabweichung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "700920db-401e-478f-b9ba-94201cafaff9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "353394fc-22cf-401a-811f-e73415107448",
   "metadata": {},
   "source": [
    "**<span style=\"font-size: 18px\">Support Vector Regressor skaliert</span>**\n",
    "\n",
    "- Erstelle Modell\n",
    "- Definiere K-Fold CV\n",
    "- Berechne und Speichere mittlere Genauigkeit und Standardabweichung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ad8649-17b9-467e-9b03-da8c5bc7db64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f39b0de3-c720-42a1-85cd-c05c3c88f887",
   "metadata": {},
   "source": [
    "**<span style=\"font-size: 18px\">Random Forest</span>**\n",
    "\n",
    "- Erstelle Modell\n",
    "- Definiere K-Fold CV\n",
    "- Berechne und Speichere mittlere Genauigkeit und Standardabweichung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a10b7a27-15d9-448a-adf3-9d972cb13b5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7a89bb43-f196-4040-9053-b213f3361b5c",
   "metadata": {},
   "source": [
    "<span style=\"font-size: 18px\">**Vergleich der Ergebnisse:**</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2fc1420-18ef-4416-b1be-c1858aa77adb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d2fcbabd-65fc-478f-a07b-c7e604df75b7",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Unüberwachtes Lernen\n",
    "\n",
    "Die **PCA** (Principal Component Analysis) ist ein Verfahren zur **Dimensionsreduktion**. Sie reduziert die Anzahl der Variablen, während die **wichtigste Varianz im Datensatz erhalten bleibt**.  \n",
    "Beim Iris-Datensatz kann PCA verwendet werden, um die vier Merkmale (Sepal-Länge/-Breite, Petal-Länge/-Breite) in zwei Hauptkomponenten zu überführen. Das erleichtert die Visualisierung und zeigt Muster im Datenraum auf.\n",
    "\n",
    "**KMeans** ist ein klassischer **Clustering-Algorithmus**. Er teilt Datenpunkte in **k Cluster**, wobei jedes Cluster durch seinen **Zentroid (Mittelpunkt)** beschrieben wird.  \n",
    "Im Iris-Datensatz können mit KMeans Cluster gebildet werden, die evtl. den drei Iris-Arten ähneln – ohne dass die Labels bekannt sein müssen.\n",
    "\n",
    "---\n",
    "\n",
    "### KMeans Clustering\n",
    "\n",
    "#### Datensatz laden\n",
    "\n",
    "Wir verwenden erneut den **Iris-Datensatz**, verzichten nun aber auf die Zielvariablen (`target`), da es sich um **unüberwachtes Lernen** handelt.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e040c0a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "import pandas as pd\n",
    "\n",
    "# Iris-Daten ohne Zielvariable laden\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "feature_names = iris.feature_names\n",
    "\n",
    "# In DataFrame umwandeln und anzeigen\n",
    "df_iris = pd.DataFrame(X, columns=feature_names)\n",
    "print(df_iris.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5de39f14-3e4b-4a5b-8e50-be3eb07b53e1",
   "metadata": {},
   "source": [
    "### Merkmalskombinationen visuell vergleichen\n",
    "\n",
    "Der Iris-Datensatz besteht aus vier numerischen Merkmalen:  \n",
    "Bei vier Merkmalen ergeben sich insgesamt **6 mögliche 2D-Kombinationen**, in denen jeweils zwei Merkmale gegenübergestellt werden können.  \n",
    "\n",
    "Diese Visualisierung zeigt alle möglichen **Paarungen der Merkmale als Streudiagramme**.  \n",
    "Einzelne Gruppen oder Muster lassen sich teilweise erkennen, jedoch ist eine **klare visuelle Trennung oder Gruppierung rein durch das Auge schwierig**, insbesondere ohne Farbcodierung nach Klassen oder Cluster.\n",
    "\n",
    "Diese Streudiagramme bieten dennoch eine erste Einschätzung möglicher Zusammenhänge oder Trennbarkeit in bestimmten Merkmalskombinationen.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec318993-86bd-4151-8bf0-d81ef5de487b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Alle Kombinationen von 2 Features\n",
    "pairs = [(0, 1), (0, 2), (0, 3),\n",
    "         (1, 2), (1, 3), (2, 3)]\n",
    "\n",
    "# 2x3 Subplots\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "\n",
    "for idx, (i, j) in enumerate(pairs):\n",
    "    ax = axes[idx // 3, idx % 3]\n",
    "    ax.scatter(X[:, i], X[:, j], s=50, alpha=0.7)\n",
    "    ax.set_xlabel(feature_names[i])\n",
    "    ax.set_ylabel(feature_names[j])\n",
    "    ax.set_title(f'{feature_names[i]} vs. {feature_names[j]}')\n",
    "    ax.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d711f972-da89-414b-9edc-c01e0cad88b6",
   "metadata": {},
   "source": [
    "Da der Iris-Datensatz drei Klassen umfasst (**Setosa**, **Versicolor**, **Virginica**), ist es sinnvoll, die Daten mithilfe der **PCA** auf **drei Dimensionen** zu reduzieren.\n",
    "\n",
    "So lässt sich ein Großteil der Varianz im Datensatz bewahren und gleichzeitig eine kompakte Repräsentation erzeugen, die sich gut für **Visualisierung** und **Clusteranalyse** eignet.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb4bee51",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# KMeans-Clustering mit 3 Clustern\n",
    "kmeans = KMeans(n_clusters=3, n_init=10, random_state=42)\n",
    "kmeans.fit(X)\n",
    "\n",
    "# Cluster-Zuweisung für jeden Datenpunkt\n",
    "cluster_labels = kmeans.labels_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9e04de0-e760-4f4a-8fa0-ecca31aa4b11",
   "metadata": {},
   "source": [
    "**<span style=\"font-size: 20px\">Validierung</span>**\n",
    "\n",
    "Für das KMeans-Clustering gibt es verschiedene Metriken zur Bewertung der Clusterqualität, darunter:\n",
    "\n",
    "- **Inertia**\n",
    "- **Silhouette Score**\n",
    "- **Calinski-Harabasz Index**\n",
    "- **Davies-Bouldin Index**\n",
    "\n",
    "Diese Metriken geben Einblicke in die Trennschärfe, Kompaktheit und Struktur der erkannten Cluster.  \n",
    "Details zu deren Anwendung in Scikit-Learn findest du in der  \n",
    "👉 [Scikit-Learn-Dokumentation zur Clusterbewertung](https://scikit-learn.org/stable/modules/clustering.html#clustering-performance-evaluation)\n",
    "\n",
    "---\n",
    "\n",
    "### Inertia\n",
    "\n",
    "Die **Inertia** misst die Summe der quadrierten Abstände aller Datenpunkte zu den Zentroiden ihrer zugewiesenen Cluster.  \n",
    "Eine **niedrige Inertia** deutet auf kompakte, gut definierte Cluster hin.  \n",
    "Eine **hohe Inertia** spricht eher für verstreute oder überlappende Gruppen.\n",
    "\n",
    "Die Inertia-Formel:\n",
    "\n",
    "$$\n",
    "\\text{Inertia} = \\sum_{j=1}^{k} \\sum_{i \\in C_j} \\|x_i - \\mu_j\\|^2\n",
    "$$\n",
    "\n",
    "Dabei ist:\n",
    "\n",
    "- \\( k \\): Anzahl der Cluster  \n",
    "- \\( C_j \\): Datenpunkte im j-ten Cluster  \n",
    "- \\( x_i \\): einzelner Datenpunkt  \n",
    "- \\( \\mu_j \\): Schwerpunkt (Zentroid) des j-ten Clusters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce6fc1fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Berechnung der Inertia für verschiedene Cluster-Anzahlen\n",
    "inertia_values = [\n",
    "    KMeans(n_clusters=k, n_init=10, random_state=42).fit(X).inertia_\n",
    "    for k in range(1, 10)\n",
    "]\n",
    "\n",
    "# In DataFrame umwandeln\n",
    "df_inertia = pd.DataFrame({\n",
    "    'Anzahl_Cluster': range(1, 10),\n",
    "    'Inertia': inertia_values\n",
    "})\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(7, 4))\n",
    "plt.plot(df_inertia['Anzahl_Cluster'], df_inertia['Inertia'], marker='o')\n",
    "plt.title(\"Elbow-Methode zur Bestimmung der Clusteranzahl\")\n",
    "plt.xlabel(\"Anzahl der Cluster (k)\")\n",
    "plt.ylabel(\"Inertia\")\n",
    "plt.grid(True)\n",
    "plt.xticks(range(1, 10))\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92561977",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialisiere das KMeans-Modell mit 3 Clustern\n",
    "kmeans = KMeans(n_clusters=3, n_init=10, random_state=42)\n",
    "\n",
    "# Trainiere das Modell auf dem vollständigen Iris-Datensatz (ohne Zielvariable)\n",
    "kmeans.fit(X)\n",
    "\n",
    "# Weist jedem Datenpunkt ein Clusterlabel (0, 1 oder 2) zu\n",
    "y_kmeans = kmeans.predict(X)\n",
    "\n",
    "# Extrahiere die berechneten Zentren der Cluster (Mittelwerte der Clusterpunkte)\n",
    "centers = kmeans.cluster_centers_\n",
    "\n",
    "# Funktion zur 2D-Visualisierung des Cluster-Ergebnisses anhand zweier Merkmale\n",
    "def plot_kmeans_clusters(X, y_labels, centroids, x_index=0, y_index=1, feature_names=None):\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    \n",
    "    # Für jedes Cluster: Streudiagramm der zugehörigen Punkte\n",
    "    for label in range(centroids.shape[0]):\n",
    "        plt.scatter(\n",
    "            X[y_labels == label, x_index],     # Punkte dieses Clusters auf X-Achse\n",
    "            X[y_labels == label, y_index],     # Punkte dieses Clusters auf Y-Achse\n",
    "            s=50,\n",
    "            label=f'Cluster {label + 1}'\n",
    "        )\n",
    "    \n",
    "    # Plot der Cluster-Zentren (Zentroide)\n",
    "    plt.scatter(\n",
    "        centroids[:, x_index],\n",
    "        centroids[:, y_index],\n",
    "        s=300,\n",
    "        marker='*',\n",
    "        c='black',\n",
    "        label='Cluster-Zentren'\n",
    "    )\n",
    "    \n",
    "    # Achsentitel ausgeben, ggf. mit echten Merkmalsnamen\n",
    "    plt.title('KMeans-Clustering (2D-Projektion)')\n",
    "    plt.xlabel(feature_names[x_index] if feature_names else f\"Feature {x_index}\")\n",
    "    plt.ylabel(feature_names[y_index] if feature_names else f\"Feature {y_index}\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Aufruf der Plotfunktion: zeige Cluster nach Sepal Length & Sepal Width\n",
    "plot_kmeans_clusters(X, y_kmeans, centers, x_index=0, y_index=1, feature_names=feature_names)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2719fc7-bb0d-4959-bb71-ff29250c9e55",
   "metadata": {},
   "source": [
    "**<span style=\"font-size: 24px\">Principle Component Analysis (PCA)</span>**\n",
    "\n",
    "**<span style=\"font-size: 20px\">Datensatz laden</span>**\n",
    "\n",
    "Wir laden hier zusätzlich die Zielvariable herunter, da wir diese zum Plotten benötigen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a657224e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "\n",
    "# Iris-Daten laden (Features und Zielvariable)\n",
    "iris = load_iris()\n",
    "X = iris.data           # Merkmalsmatrix\n",
    "\n",
    "color = iris.target     # Klassenlabels (für Farbzuweisung beim Plotten)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0654d9cc-c5bc-4471-a2f8-59f0495c717a",
   "metadata": {},
   "source": [
    "**<span style=\"font-size: 20px\">Erklärte Varianz</span>**\n",
    "\n",
    "Die kumulierte Erklärte Varianz (Cumulative Variance Ratio) in der PCA ist ein Maß dafür, wie viel Information von den ursprünglichen Daten in den Hauptkomponenten erhalten bleibt. Es zeigt den Anteil der gesamten Varianz im Datensatz an, der von den ersten k Hauptkomponenten erklärt wird. Je höher der Wert, desto besser erfassen die Hauptkomponenten die Variationen im Datensatz.\n",
    "\n",
    "Wenn die kumulierte erklärte Varianz 0,98 beträgt, bedeutet dies, dass die ersten k Hauptkomponenten zusammen 98 % der gesamten Varianz im Datensatz erklären. Mit anderen Worten, diese Hauptkomponenten erfassen einen Großteil der Variationen in den Daten und bieten eine gute Zusammenfassung des Datensatzes. Dies ist oft ein Hinweis darauf, dass eine Reduktion der Dimensionen auf k Hauptkomponenten eine sinnvolle Wahl sein könnte, da sie die Daten mit relativ hoher Genauigkeit darstellen können.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b9f96b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "# PCA durchführen und kumulierte erklärte Varianz berechnen\n",
    "pca = PCA().fit(X)\n",
    "cumulative_variance_ratio = np.cumsum(pca.explained_variance_ratio_)\n",
    "\n",
    "# Plot erstellen\n",
    "plt.figure(figsize=(6, 3))\n",
    "plt.plot(range(1, len(cumulative_variance_ratio) + 1), cumulative_variance_ratio, marker='o')\n",
    "plt.xlabel('Anzahl der Komponenten')\n",
    "plt.ylabel('Kumulierte erklärte Varianz')\n",
    "plt.title('Kumulierte erklärte Varianz vs. Anzahl der PCA-Komponenten')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fcedd40",
   "metadata": {},
   "source": [
    "**<span style=\"font-size: 20px\">Dimensionsreduktion</span>**\n",
    "\n",
    "Im nächsten Schritt wird die Anzahl der Merkmale mithilfe der PCA auf zwei bzw. drei Hauptkomponenten reduziert. Ziel ist es, die Daten kompakter darzustellen und gleichzeitig möglichst viel Varianz beizubehalten – ideal für Visualisierung und Clusteranalyse.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b26410f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.decomposition import PCA\n",
    "import pandas as pd\n",
    "\n",
    "# Iris-Daten laden (nur Features und Zielvariable für Visualisierung)\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "color = iris.target\n",
    "\n",
    "# PCA mit 3 Hauptkomponenten durchführen\n",
    "pca = PCA(n_components=3)\n",
    "X_pca = pca.fit_transform(X)\n",
    "\n",
    "# In DataFrame umwandeln für bessere Übersicht\n",
    "X_pca = pd.DataFrame(X_pca, columns=['PC1', 'PC2', 'PC3'])\n",
    "\n",
    "# Formen vergleichen\n",
    "print(\"Ursprüngliche Form der Daten:\", X.shape)\n",
    "print(\"Transformierte Form (PCA):    \", X_pca.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53813f27-d536-4466-acd1-a0ca9f8a7fff",
   "metadata": {},
   "source": [
    "**<span style=\"font-size: 20px\">Visualisierung</span>**\n",
    "\n",
    "Die Funktion `plot_combined_3d` erzeugt eine kombinierte Darstellung aus einem **3D-Scatterplot** (oben) und drei **2D-Scatterplots** (unten).\n",
    "\n",
    "- Der 3D-Plot zeigt die Datenpunkte im Raum der ersten drei Hauptkomponenten (PC1–PC3).\n",
    "- Die 2D-Plots visualisieren jeweils die Beziehung zwischen zwei dieser Komponenten: PC1 vs. PC2, PC1 vs. PC3 und PC2 vs. PC3.\n",
    "\n",
    "Diese Darstellung hilft, Strukturen, Trennbarkeit oder potenzielle Cluster im reduzierten Merkmalsraum zu erkennen.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1813d14-664e-48c8-b518-92814c84fac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "def plot_combined_3d(X_pca, color):\n",
    "    # Abbildung erzeugen\n",
    "    fig = plt.figure(figsize=(12, 8))\n",
    "    \n",
    "    # Oberer Plot: 3D-Scatterplot der ersten drei Hauptkomponenten\n",
    "    ax_3d = fig.add_subplot(2, 1, 1, projection='3d')\n",
    "    scatter_3d = ax_3d.scatter(\n",
    "        X_pca[:, 0], X_pca[:, 1], X_pca[:, 2],\n",
    "        c=color, cmap='viridis', s=50, alpha=0.8\n",
    "    )\n",
    "    ax_3d.set_xlabel('PC1')\n",
    "    ax_3d.set_ylabel('PC2')\n",
    "    ax_3d.set_zlabel('PC3')\n",
    "    ax_3d.set_title('PCA – 3D-Darstellung der ersten drei Hauptkomponenten')\n",
    "\n",
    "    # Untere Plots: alle 2D-Projektionen der drei PCs\n",
    "    for i, (x_axis, y_axis) in enumerate([(0, 1), (0, 2), (1, 2)]):\n",
    "        ax = fig.add_subplot(2, 3, i + 4)\n",
    "        ax.scatter(\n",
    "            X_pca[:, x_axis], X_pca[:, y_axis],\n",
    "            c=color, cmap='viridis', s=40, alpha=0.8\n",
    "        )\n",
    "        ax.set_xlabel(f'PC{x_axis + 1}')\n",
    "        ax.set_ylabel(f'PC{y_axis + 1}')\n",
    "        ax.grid(True)\n",
    "\n",
    "    # Abstand optimieren\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Aufruf der Funktion (kompatibel mit DataFrame oder NumPy-Array)\n",
    "plot_combined_3d(X_pca.values if isinstance(X_pca, pd.DataFrame) else X_pca, color)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b8cee8c-88b2-47ae-91d0-90de716c458b",
   "metadata": {},
   "source": [
    "**<span style=\"font-size: 18px; color: orange;\">Optional: Interaktive Visualisierung mit Plotly</span>**\n",
    "\n",
    "Die Bibliothek **Plotly** ermöglicht interaktive Diagramme, in denen man z. B. zoomen, rotieren und Datenpunkte dynamisch untersuchen kann.\n",
    "\n",
    "Um Plotly zu verwenden, muss es zunächst installiert werden (falls noch nicht geschehen):\n",
    "\n",
    "```bash\n",
    "pip install plotly\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be3eaa2a-36ee-457c-9cc4-91789d9ca0c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "# Interaktiver 3D-Scatterplot mit Plotly\n",
    "fig = go.Figure(data=[go.Scatter3d(\n",
    "    x=X_pca['PC1'],\n",
    "    y=X_pca['PC2'],\n",
    "    z=X_pca['PC3'],\n",
    "    mode='markers',\n",
    "    marker=dict(\n",
    "        color=color,             # Farbzuordnung über Klassenlabels\n",
    "        colorscale='viridis',    # Farbschema\n",
    "        size=5,                  # Punktgröße\n",
    "        opacity=0.8              # leichte Transparenz für Überlappung\n",
    "    )\n",
    ")])\n",
    "\n",
    "# Layout-Anpassung: Achsentitel, gleiches Seitenverhältnis\n",
    "fig.update_layout(\n",
    "    scene=dict(\n",
    "        xaxis_title='PC1',\n",
    "        yaxis_title='PC2',\n",
    "        zaxis_title='PC3',\n",
    "        aspectmode='cube'  # gleichmäßiges Seitenverhältnis\n",
    "    ),\n",
    "    title='PCA – Interaktiver 3D-Scatterplot mit Plotly',\n",
    "    margin=dict(l=0, r=0, b=0, t=40)\n",
    ")\n",
    "\n",
    "# Plot anzeigen\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4578d4e4",
   "metadata": {},
   "source": [
    "## 2.3 Kombination PCA und Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae343f4",
   "metadata": {},
   "source": [
    "## <font color='red'>Aufgabe:</font>\n",
    "\n",
    "Die Kombination aus **PCA** und **Clustering** ermöglicht es, Muster in hochdimensionalen Daten zu erkennen, die in der Originaldarstellung nur schwer sichtbar sind.\n",
    "\n",
    "Zunächst wird die Dimensionalität der Daten mit **PCA** reduziert. Anschließend wird ein **Clustering-Verfahren** (z. B. KMeans) auf den transformierten Daten (`X_pca`) angewendet.\n",
    "\n",
    "📌 **Ziel:**  \n",
    "Führe das Clustering nicht auf den Originaldaten `X`, sondern auf den **dimensionsreduzierten PCA-Daten `X_pca`** durch.  \n",
    "Die resultierenden Cluster-Labels (`kmeans.predict(...)`) sollen zur **farblichen Darstellung im Scatterplot** verwendet werden.\n",
    "\n",
    "---\n",
    "\n",
    "### ✅ Checkpoints:\n",
    "\n",
    "- [ ] **Daten laden** (`X`, `target`)  \n",
    "- [ ] **PCA anwenden** (`X_pca` mit 3 Hauptkomponenten)  \n",
    "- [ ] **KMeans auf `X_pca` anwenden** (Cluster-Labels berechnen)  \n",
    "- [ ] **Scatterplot erstellen** (z. B. mit Plotly oder Matplotlib)  \n",
    "- [ ] **Clustering-Ergebnis interpretieren** (visuell oder mit Metriken wie Silhouette Score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf1f3ec3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9374162e-2a75-423c-b0da-f49cf26a2c87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ed42c4-8f37-4f19-980b-b541e30fed27",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
