{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "97672b46",
   "metadata": {},
   "source": [
    "# Geodatenanalyse 2: Zeitreihenvorhersage und rekurrente neuronale Netze\n",
    "\n",
    "## Zeitreihenvorhersage mit 1D-CNN\n",
    "\n",
    "Ziel der Übung: Grundwasserstand simulieren für einen Zeitraum von 4 Jahren basierend auf meteorologischen Inputdaten (z.B. Niederschlag und Lufttemperatur). \n",
    "\n",
    "Mithilfe von NN können wir den Zusammenhang zwischen aufeinanderfolgenden Niederschlagsereignissen und dem vergangenen Temperaturverlauf mit dem Grundwasserstand herstellen, auch ohne die direketen Prozesse (Grundwasserneubildung, Evapotranspiration, ...) zu definieren. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "044f65ca",
   "metadata": {},
   "source": [
    "### Packages einladen und Seed setzen\n",
    "Um ein reproduzierbares Ergebnis zu erhalten definieren wir zunächst die Startpunkte (seeds) der Zufallszahlengeneratoren von numpy und tensorflow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7d3eeb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import tensorflow as tf\n",
    "from keras.layers import Input, LSTM, Dense, Conv1D, MaxPooling1D, Flatten\n",
    "from keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam \n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "#set random seed for reproducability\n",
    "from numpy.random import seed\n",
    "seed(42) # this is a randomly chosen number\n",
    "\n",
    "from tensorflow import random\n",
    "random.set_seed(42) # this is also a randomly chosen number\n",
    "\n",
    "print(\"seeds are set\") # Outputs the text \"seeds are set\" to confirm that the seeds have been successfully set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38376dea",
   "metadata": {},
   "source": [
    "### Daten einladen\n",
    "Die (wöchentlich) Grundwasserdaten befinden sich in der Datei: **GW-Data.csv**  \n",
    "Die (wöchentlichen) meteorologischen Inputdaten in der Datei: **Climate-Data.csv**\n",
    "\n",
    "Wir laden die Dateien als pandas Dataframe mit einem Zeitindex (datetime) ein und führen beide Dateien zusammen. Ein weiteres Preprocessing ist in diesem Fall nicht nötig, da die Daten schon auf Datenlücken/Fehlwerte etc. untersucht und bereinigt wurden. Auch decken alle Daten den gleichen Zeitraum ab und verfügen über ein identisches Sampling Intervall (wöchentlich)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a2950a",
   "metadata": {},
   "outputs": [],
   "source": [
    "GWData = pd.read_csv('./GW-Data.csv', #reads the CSV files GW-Data.csv into Panda's DataFrame.\n",
    "                     parse_dates=['Date'], #ensures that the Date column is recognised as a date and converted accordingly\n",
    "                     index_col=0, #sets the first column of the CSV file as the index of the DataFrame\n",
    "                     dayfirst = True, # specifies that the date format is day-month-year\n",
    "                     decimal = '.', #specifies that the decimal point is used\n",
    "                     sep=',') #indicates that the comma is used as the column separator\n",
    "\n",
    "ClimateData = pd.read_csv('Climate-Data.csv', parse_dates=['Date'],index_col=0,dayfirst = True, decimal = '.', sep=',')\n",
    "\n",
    "# Merge the Dataframes\n",
    "data = pd.merge(GWData, ClimateData, how='inner', left_index = True, right_index = True) \n",
    "# merges the two DataFrames GWData and ClimateData based on their indices. how='inner' means that only the common entries of both DataFrames are included in the result\n",
    "\n",
    "\n",
    "\n",
    "#plot GWL data\n",
    "plt.figure(figsize=(10,3)) #Creates a new graphic with the specified dimensions\n",
    "plt.plot(data.index, data['GWL'], 'k', label =\"GWL\", linewidth = 1.7) #plots the GWL data (groundwater level) against time (data.index). The colour of the line is black ('k') and the linewidth is 1.7\n",
    "plt.title(\"GWL Data\", size=17,fontweight = 'bold') #Sets the title of the plot with font size 17 and bold font\n",
    "plt.ylabel('GWL [m asl]', size=15) #Labels the y-axis with GWL [m asl] and font size 15\n",
    "plt.xlabel('Date',size=15)# Labels the x-axis with Date and font size 15\n",
    "plt.legend(fontsize=15,loc='upper right',fancybox = False, framealpha = 1, edgecolor = 'k')#adds a legend to the plot with font size 15, positioned upper right, without rounded corners (fancybox=False), an opacity of 1 and a black border (edgecolor='k')\n",
    "plt.tight_layout() #djusts the layout of the graphic to avoid overlapping.\n",
    "plt.grid(visible=True, which='major', color='#666666', alpha = 0.3, linestyle='-') #Adds a grid to the plot showing the major lines (major), with a grey colour, opacity of 0.3 and solid lines\n",
    "plt.xticks(fontsize=14)\n",
    "plt.yticks(fontsize=14)#Sets the font size of the x-axis and y-axis labels to 14\n",
    "plt.show() #Displays the plot\n",
    "\n",
    "#inspect the data\n",
    "data.head() \n",
    "#displays the first five lines of the DataFrame data. This is useful to get a quick overview of the data and to ensure that the data was read in and merged correctly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fbc95ce",
   "metadata": {},
   "source": [
    "Der DataFrame setzt sich nun zusammen aus der Indexspalte **Date**, dem Grundwasserstand **GWL**, Niederschlag **P**, relativer Feuchte **rH**, Temperatur **T** und einem geglätteten Temperatursignal **Tsin** (Sinuskurve an T gefittet).  \n",
    "\n",
    "Parameter **rH** und **Tsin** werden zunächst nicht benötigt (*drop*)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5fba80f",
   "metadata": {},
   "outputs": [],
   "source": [
    "try: #Starts a try block\n",
    "    data = data.drop(columns=['rH','Tsin']) #removes the columns rH and Tsin from the DataFrame\n",
    "    print(\"dropped\") #if the columns have been successfully removed, \"dropped\" is output\n",
    "except: #If an error occurs when attempting to remove the columns (e.g. if the columns have already been removed or do not exist), the except block is executed\n",
    "    print(\"⚠️columns already dropped\") #if an error occurs, \"already dropped\" is output\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f678b6ae",
   "metadata": {},
   "source": [
    "die *try ... except* - Syntax verhindert einen Fehler, wenn die Variablen nicht vorhanden sind oder schon entfernt wurden. In unserem Fall also z.B. wenn die Zelle im notebook bereits ausgeführt wurde.  \n",
    "\n",
    "Wie immer führen viele Wege zum Ziel. Man könnte auch schreiben\n",
    "- data.drop(columns=['rH','Tsin'], inplace = True)\n",
    "- data = data.drop(['rH','Tsin'], axis = 1)\n",
    "- ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3a92599",
   "metadata": {},
   "source": [
    "### Wir benutzen keine Einzelwerte als Inputs sondern Sequenzen!\n",
    "\n",
    "Zunächst müssen wir also die **Input-Sequenzlänge** festlegen und die Daten so umwandeln, dass jedem GWL-Wert Sequenzen von P- und T-Werten in der entsprechenden Sequenzlänge zugeordnet sind. Wir bezeichen diesen Parameter im Folgenden als **seq_length** (*Anzahl der Input Zeitschritte*).\n",
    "\n",
    "Hierfür definieren wir eine Funktion die genau das für uns erledigt und die wir immer wieder verwenden können: *make_sequences*    \n",
    "\n",
    "Diese können wir nachher mit folgender Zeile aufrufen:  \n",
    "*X,Y = make_sequences(data, seq_length)*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e536a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_sequences(data, seq_length): #Defines a function make_sequences that takes two arguments: data, seq_length\n",
    "#     \"\"\" docstring \"\"\"\n",
    "#     data: numpy array with target (Y) in first column and model inputs in following columns\n",
    "#     n_steps_in: number that defines the sequence length\n",
    "    \n",
    "#     Output:\n",
    "#     X: sequenced model input data\n",
    "#     Y: sequenced model target data\n",
    "    \n",
    "#     function modified after: machinelearningmastery.com\n",
    "#     \"\"\"\n",
    "    \n",
    "    #sequence the data\n",
    "    X, Y = list(), list() #Initialises two empty lists X and Y to store the sequenced input and output data. They automatically adjust their size when elements are added. Another way to create empty lists would be X, Y = [],[]\n",
    " \n",
    "    for i in range(len(data)): #Iterates through the data set, one time step at a time\n",
    "        end_idx = i + seq_length #Calculates the end index of the current sequence\n",
    "        if end_idx >= len(data): #Checks whether the end index goes beyond the end of the data set. If yes, the loop is cancelled\n",
    "            break\n",
    "        seq_x = data[i:end_idx, 1:] #Extracts the input sequence. This includes all columns except the first, from the current index i to end_idx\n",
    "        seq_y = data[end_idx, 0] #Extracts the target value. This is the value in the first column at end_idx\n",
    "        X.append(seq_x) #Adds the input sequence seq_x to the list X\n",
    "        Y.append(seq_y) #Adds the target value seq_y to the list Y\n",
    "        \n",
    "    return np.array(X), np.array(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03b57184",
   "metadata": {},
   "source": [
    "### Daten splitten\n",
    "\n",
    "Bevor wir die Daten in Sequenzen umwandeln, müssen wir aber zunächst noch den bekannten Train-Test-Split durchführen und die Daten anschließend skalieren. Wichtig, shuffling ist für Zeitreihen nicht erlaubt, wir teilen die Zeitreihe einfach in zusammenhängende Abschnitte auf. Hierfür können die bereits eingeführten Funktionen verwendet werden **ABER** besonders bei Zeitreihen bietet es sich häufig an, die Zeitpunkte an denen geteilt wird, selbst festzulegen. Es ist einfach häufig sinnvoller mit Jahren als mit prozentualen Anteilen einer Zeitreihe zu arbeiten.\n",
    "\n",
    "Daher teilen wir nun die Zeitreihe in drei Abschnitte auf:  \n",
    "**Training, Early Stopping (Validation) und Testing**  \n",
    "\n",
    "Zum Testen sollen die Jahre 2012 bis einschließlich 2015 (also 4 Jahre) verwendet werden, für Early Stopping 2 Jahre (2010 - 2011), fürs Training die restlichen Daten davor.\n",
    "\n",
    "Hierfür können wir den Datumsindex des Dataframe verwenden. Zunächst definieren wir uns jedoch ein Datum, zu welchem Die Daten geteilt werden sollen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "920b7984",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_startdate = pd.to_datetime('01012010', format='%d%m%Y') # converts the character string into a timestamp object from Pandas\n",
    "print(\"Start Stopset\")\n",
    "print(val_startdate)\n",
    "\n",
    "test_startdate = pd.to_datetime('01012012', format='%d%m%Y')\n",
    "print(\"\\nStart Testset\") #\\n stays for new line\n",
    "print(test_startdate)\n",
    "\n",
    "TrainingData = data[(data.index < val_startdate)] #Filters the data to get all data points before val_startdate \n",
    "StopData = data[(data.index >= val_startdate) & (data.index < test_startdate)] # Filters the data to get all data points between the val_startdate (inclusive) and the test_startdate (1 January 2012, exclusive)\n",
    "TestData = data[(data.index >= test_startdate)] #Filters the data to obtain all data points from the test_startdate (inclusive). This data is used for testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "276e9274",
   "metadata": {},
   "source": [
    "#### Überlappung beim Split notwendig!\n",
    "\n",
    "Beim Teilen gilt es die eben angesprochene Sequenzlänge *seq_length* zu beachten, denn wenn die Zeitreihe zum 1.1.2012 geteilt werden sollen, so werden aus dem Jahr 2012 noch *seq_length* Zeitschritte benötigt um den ersten Wert in 2012 berechnen zu können. Die Zeiträume überlappen sich also in Bezug auf die Inputdaten *X* ( *_ext* = extended). \n",
    "\n",
    "Beispiel: Tagesdaten und beliebiges Modell mit *seq_length = 4*:\n",
    "\n",
    "       28.12.2011   X        Beginn Überlapp  \n",
    "       29.12.2011   X  X\n",
    "       30.12.2011   X  X  X\n",
    "       31.12.2011   X  X  X\n",
    "       1.1.2012     Y  X  X  Beginn Testzeitraum\n",
    "       2.1.2012        Y  X\n",
    "       3.1.2012           Y\n",
    "       [...]\n",
    "\n",
    "Für den Trainigsdatensatz gilt entsprechend, dass der erste simulierte Wert erst nach *n_steps_in* Zeitschritten berechnet, wird. Die bis dahin ungenutzten Zielwerte werden verworfen. Bei großen Sequenzlängen kann hierdurch der Trainingszeitraum also u.U. wesentlich verkleinert werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a63c6121",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_length = 30 #Defines the number of steps (time steps) that should be contained in the input sequence\n",
    "                                              \n",
    "StopData_ext = pd.concat([TrainingData.iloc[-seq_length:], StopData], axis=0) #takes last steps of TrainingData and combines it with StopData\n",
    "TestData_ext = pd.concat([StopData.iloc[-seq_length:], TestData], axis=0) #takes last steps of StopData and combines it with TestData\n",
    "\n",
    "print(StopData_ext) #Outputs the extended validation data set (StopData_ext), which now starts n_steps_in time steps before the original val_startdate\n",
    "print(TestData_ext) #Outputs the extended test data set (TestData_ext), which now starts n_steps_in time steps before the original test_startdate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f32165ea",
   "metadata": {},
   "source": [
    "### Daten skalieren \n",
    "Jetzt skalieren wir die Daten auf den Wertebereich [-1,1] entsprechend des Trainingdatensatzes. Wie in der letzten Übung erstellen wir noch einen scaler der nur die Zielvariable scaled um nachher einfacher retransformieren zu können (*scaler_gwl*)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9612b943",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fit scaler\n",
    "scaler = MinMaxScaler(feature_range=(-1, 1)) #Initialises a MinMaxScaler with a value range from -1 to 1\n",
    "scaler.fit(TrainingData) #Adapts the scaler to the TrainingData, i.e. the scaler calculates the minimum and maximum values of the TrainingData in order to later transform the data into the range from -1 to 1\n",
    "\n",
    "scaler_gwl = MinMaxScaler(feature_range=(-1, 1)) #Initialises a separate MinMaxScaler for the GWL data \n",
    "scaler_gwl.fit(pd.DataFrame(TrainingData['GWL'])) #Adapts the scaler to the GWL column of the TrainingData. Here, pd.DataFrame is used to ensure that the GWL column is in the correct format (as a DataFrame instead of a Series)\n",
    "\n",
    "#scale data\n",
    "TrainingData_n = scaler.transform(TrainingData) #Transforms the TrainingData by scaling the values in the range from -1 to 1\n",
    "StopData_ext_n = scaler.transform(StopData_ext) #Transforms the extended validation data (StopData_ext)\n",
    "TestData_ext_n = scaler.transform(TestData_ext) #Transforms the extended test data (TestData_ext)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8934a815",
   "metadata": {},
   "source": [
    "Nun nutzen wir die Sequenz Funktion von oben, aus einem 2D (Länge Datensatz, Anzahl Parameter) wird damit ein 3D Datensatz mit den Dimensionen: (Länge Datensatz, seq_length (Input Sequenzlänge), Anzahl Input Parameter).\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc3a46a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creates sequences from the scaled training, validation and test data using the make_sequences function\n",
    "X_train,Y_train = make_sequences(np.asarray(TrainingData_n), seq_length)\n",
    "X_stop,Y_stop = make_sequences(np.asarray(StopData_ext_n), seq_length)\n",
    "X_test,Y_test = make_sequences(np.asarray(TestData_ext_n), seq_length)\n",
    "\n",
    "print(\"(Länge Datensatz, Input Sequenzlänge, Anzahl Input Parameter)\\n\")\n",
    "print(\"Train Input: {} \\nTrain Target: {} \\n\".format(X_train.shape, Y_train.shape)) #dimensions of these sequences and target values to ensure that the data has been prepared correctly\n",
    "print(\"Validation Input: {} \\nValidation Target: {} \\n\".format(X_stop.shape, Y_stop.shape))\n",
    "print(\"Test Input: {} \\nTest Target: {} \\n\".format(X_test.shape, Y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c78218b",
   "metadata": {},
   "source": [
    "### Modell erstellen und kompilieren \n",
    "Diese Daten können wir nun direkt in das Modell eingeben. Dieses definieren wir im Folgenden. Wir starten mit einem **1D-CNN** und nutzen hierfür die Keras API in Tensorflow (*tensorflow.keras*):\n",
    "\n",
    "from keras.layers import Input, Dense, Conv1D, MaxPooling1D, Flatten, LSTM\n",
    "\n",
    "from keras.models import Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a76afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set seed for reproducability\n",
    "seed(42) \n",
    "tf.random.set_seed(42)\n",
    "\n",
    "#Start with Input Layer (ensures that the subsequent layers receive the data in the correct form)\n",
    "inp = Input(shape=(seq_length, X_train.shape[2])) #The inputs have a sequence length of seq_length and X_train.shape[2] features \n",
    "\n",
    "#1D Conv Layer (connect it to Input Layer (inp))\n",
    "#extracts features from the input sequences. Patterns and local dependencies in the data can be recognised through convolution\n",
    "cnn = Conv1D(filters=256, #define number of filters\n",
    "                             kernel_size=3, #define kernel_size\n",
    "                             activation='relu', #set activation to 'relu' (outputs only positive numbers) for better performance and to add non-linearity \n",
    "                             padding='same')(inp) #define same padding and connect to 'inp' Layer \n",
    "\n",
    "#Pooling Layer (connect it to the previous layer (conv))\n",
    "cnn = MaxPooling1D(padding='same')(cnn) #Consolidates the information from the feature map by selecting the largest values in each pooling window. This reduces the dimension of the data and helps to highlight the most important features\n",
    "\n",
    "\n",
    "#Flatten Layer (connect it to the previous layer (pool))\n",
    "cnn = Flatten()(cnn) #converts the output of the previous layer into a flat vector.This is necessary to prepare the data for the subsequent dense layers (fully connected layers)\n",
    "\n",
    "\n",
    "#add a dense layer (connect it to the previous layer (flat))\n",
    "dense = Dense(30, activation='relu')(cnn) #learns more complex relationships through the non linearity of relu acitvation \n",
    "\n",
    "\n",
    "#add 1 output neuron (1 GWL Prediction) (connect it with the previous layer (dense))\n",
    "output = Dense(1, activation='linear')(dense) #activation = 'linear' ensures that the output value is not restricted and can assume any real value\n",
    "\n",
    "#Creates a model that merges the defined layers.\n",
    "model = Model(inputs=inp, outputs=output)\n",
    "\n",
    "#define optimizer\n",
    "optimizer = Adam(learning_rate=1E-3, epsilon=1E-3, clipnorm=True)\n",
    "  \n",
    "#compile the model\n",
    "model.compile(loss='mse', optimizer=optimizer, metrics=['mse'])\n",
    "\n",
    "#print model summary to inspect the model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d7e381-bfba-4cb1-b840-e9c6633c0f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ########### this part does the exact same thing as the lines above and corresponds to what you have learned last time ##########\n",
    "# model = tf.keras.Sequential()\n",
    "# model.add(tf.keras.Input(shape=(n_steps_in, X_train.shape[2]))) # define the shape of the input data\n",
    "# model.add(tf.keras.layers.Conv1D(filters=256,kernel_size=3,activation='relu',padding='same')) #start with a 1D-Conv Layer\n",
    "# model.add(tf.keras.layers.MaxPool1D(padding='same')) #add Pooling Layer\n",
    "# model.add(tf.keras.layers.Flatten())#reshape data for next layer\n",
    "# model.add(tf.keras.layers.Dense(30, activation='relu')) # add a dense layer\n",
    "# model.add(tf.keras.layers.Dense(1, activation='linear')) # output neuron to get meaningful output values\n",
    "# ####################################################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63fff065-08b9-490b-b262-277e0f4ed2b6",
   "metadata": {},
   "source": [
    "### Modell trainieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12052240",
   "metadata": {},
   "outputs": [],
   "source": [
    "#early stopping callback that ends the training if the validation loss does not improve. It restores the best weights when the training is stopped\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=0, patience=20, restore_best_weights = True)\n",
    "\n",
    "#Trains the model with the training data and validates it with the validation data. The training is carried out with a batch size of 32 and an early stopping callback\n",
    "history = model.fit(X_train, Y_train,validation_data=(X_stop, Y_stop), epochs=100, verbose=3,\n",
    "                    batch_size=32, callbacks=[es])\n",
    "\n",
    "#plot training loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.legend(['training loss','validation loss'])\n",
    "plt.title('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfcdd27e",
   "metadata": {},
   "source": [
    "Jetzt haben wir ein fertig trainiertes Modell, das wir zur Simulation von ungesehenen Daten (TestData) verwenden können.\n",
    "\n",
    "### Tesdaten vorhersagen\n",
    "\n",
    "Wir geben dafür *X_test* in das Modell und vergleichen die Vorhersage (sim) mit dem tatsächlich gemessenen Y_test (obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "699c925f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim = model.predict(X_test) #Makes predictions with the trained model model on the test input X_test\n",
    "\n",
    "#rescale simulated and observed values\n",
    "sim = scaler_gwl.inverse_transform(sim)  \n",
    "obs = scaler_gwl.inverse_transform(Y_test.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73f80ab9",
   "metadata": {},
   "source": [
    "### Fehlerwerte berechnen und Vorhersage plotten "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8c6620c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Nash-Sutcliffe-Efficiency: NSE (NSE evaluates the prediction accuracy compared to the mean observation)\n",
    "NSE = 1 - ((np.sum((sim-obs) ** 2)) / (np.sum((obs - np.mean(obs)) ** 2)))\n",
    "\n",
    "#Root Mean Squared Error\n",
    "RMSE =  np.sqrt(np.mean((sim-obs) ** 2))\n",
    "\n",
    "#Pearson r\n",
    "r = stats.pearsonr(sim[:,0], obs[:,0])\n",
    "r = r[0] #r\n",
    "\n",
    "#Bias\n",
    "Bias = np.mean(sim-obs)\n",
    "\n",
    "scores = pd.DataFrame(np.array([[NSE, RMSE, r, Bias]]),\n",
    "                      columns=['NSE','RMSE','r','Bias']) #Saves the calculated metrics (NSE, RMSE, r, bias) in a Pandas DataFrame scores\n",
    "\n",
    "#Plot results\n",
    "plt.figure(figsize=(13,3))\n",
    "plt.plot(TestData.index, sim, 'r', label =\"simulated\", linewidth = 1.7)\n",
    "plt.plot(TestData.index, obs, 'k', label =\"observed\", linewidth=1.7,alpha=0.9)\n",
    "\n",
    "plt.title(\"Simulation of TestData\", size=17,fontweight = 'bold')\n",
    "plt.ylabel('GWL [m asl]', size=15)\n",
    "plt.xlabel('Date',size=15)\n",
    "plt.legend(fontsize=15,bbox_to_anchor=(1.2, 1),loc='upper right',fancybox = False, framealpha = 1, edgecolor = 'k')\n",
    "plt.tight_layout()\n",
    "plt.grid(visible=True, which='major', color='#666666', alpha = 0.3, linestyle='-')\n",
    "plt.xticks(fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "plt.show()\n",
    "\n",
    "#show scores\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e98313a3",
   "metadata": {},
   "source": [
    "### Regularisierungstechniken - robuste Modelle\n",
    "\n",
    "Overfitting und Robustness sind zentrale Punkte für das Training von ANNs. Neben einem klassischen Early Stopping gegen Overfitting gibt es noch weitere Ansätze.\n",
    "\n",
    "#### Batch-Normalization Layer\n",
    "\n",
    "*tf.keras.layers.BatchNormalization()*  \n",
    "https://www.tensorflow.org/versions/r2.7/api_docs/python/tf/keras/layers/BatchNormalization\n",
    "\n",
    "Ihr kennt bereits das Vanishing Gradient Problem. BatchNorm Layer verhindern jetzt im Prinzip das Gegenteil, nämlich **Exploding Gradients**. Im Grunde wird dafür lediglich der Output des vorhergehenden Layers normalisiert.\n",
    "Dies hat den Effekt, dass der Lernprozess stabilisiert und die Anzahl der Trainingsepochen, die zum Trainieren von Deep ANN benötigt werden, drastisch reduziert wird.\n",
    "\n",
    "Mehr (ausführliche) Infos hier: https://machinelearningmastery.com/batch-normalization-for-training-of-deep-neural-networks/  oder hier: https://towardsdatascience.com/batch-normalization-the-greatest-breakthrough-in-deep-learning-77e64909d81d\n",
    "\n",
    "#### Dropout Layer\n",
    "\n",
    "*tf.keras.layers.Dropout(rate)*  \n",
    "https://www.tensorflow.org/versions/r2.7/api_docs/python/tf/keras/layers/Dropout\n",
    "\n",
    "Durch einen Dropout Layer werden im Grunde ein definierter Anteil der möglichen Pfade im Netzwerk an dieser Stelle zufällig deaktiviert (zufällig immer andere bei jedem Durchlauf). Dadurch wird das Training verrauscht und die Nodes innerhalb einer Schicht gezwungen, besser auf Inputs zu reagieren.\n",
    "\n",
    "\n",
    "#### Gaußian-Noise Layer\n",
    "Prinzip: Den Daten wird Rauschen hinzugefügt, sodass das Model die Zusammenhänge robuster lernen kann. Wird heute nicht in dieser Übung behandelt.  \n",
    "https://keras.io/api/layers/regularization_layers/ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb90cfdf",
   "metadata": {},
   "source": [
    "### Aufgabe 1: CNN\n",
    "\n",
    "Macht euch mit dem Modell vertraut und verändert einmal folgende Parameter:  \n",
    "- Anzahl der Inputparameter\n",
    "- seq_length\n",
    "- Anzahl der Filter im 1D-Conv Layer\n",
    "- Training batch size\n",
    "- Epochenanzahl und Early Stopping Patience\n",
    "\n",
    "Wie ändert sich die Vorhersagegüte? Was für einenen NSE könnt ihr erreichen?\n",
    "\n",
    "Was passiert wenn ihr die Lernrate auf 1E-4 herabsetzt und was ist eine mögliche Erklärung dafür, wenn ihr an die erste Vorlesung zu künstlichen neuronalen Netzen (wie diese trainiert werden/wie diese lernen) denkt?"
   ]
  },
  {
   "attachments": {
    "54cfd975-ed2c-4a2c-8fe8-0991471fa732.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "fd6241cc",
   "metadata": {},
   "source": [
    "### Aufgabe 2: LSTM\n",
    "Ersetzt das 1D-CNN Modell durch ein LSTM. \n",
    "Hinweis: orientiert euch an folgender Struktur:\n",
    "\n",
    "\n",
    "![image.png](attachment:54cfd975-ed2c-4a2c-8fe8-0991471fa732.png)\n",
    "\n",
    "Ihr müsst also folgendes definieren:\n",
    "2. Input Layer\n",
    "3. LSTM Layer\n",
    "4. Dense Layer\n",
    "5. Dense Layer mit einem Output Neuron\n",
    "(kein Pooling und kein Flatten Layer!)\n",
    "\n",
    "Hier könnt ihr außerdem die Syntax für den LSTM Layer nachlesen:\n",
    "https://www.tensorflow.org/versions/r2.7/api_docs/python/tf/keras/layers/LSTM (TF2.7)  \n",
    "https://www.tensorflow.org/api_docs/python/tf/keras/layers/LSTM (aktuellste TF Version)\n",
    "\n",
    "Hinweis: **ihr müsst im LSTM layers nur \"units\" definieren**. Den Rest könnt ihr entsprechend den default Einstellungen nutzen.  \n",
    "*LSTM(units)*\n",
    "\n",
    "\n",
    "Welches des beiden Modelle erzielt eine bessere Performance? Fallen euch sonst Unterschiede auf, ist z.B. eines der Modelle schneller?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad6d7f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set seed\n",
    "seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "################################################################### 1D CNN Modell from above\n",
    "#Input Layer\n",
    "inp = Input(shape=(seq_length, X_train.shape[2]))\n",
    "\n",
    "# #1D-Conv Layer\n",
    "cnn = Conv1D(filters=256, kernel_size=3, activation='relu', padding='same')(inp)\n",
    "\n",
    "# #Pooling Layer\n",
    "cnn = MaxPooling1D(padding='same')(cnn) \n",
    "\n",
    "#Flatten Layer\n",
    "cnn = Flatten()(cnn) \n",
    "\n",
    "#Dense layer\n",
    "dense =Dense(30, activation='relu')(cnn)\n",
    "\n",
    "#Output Layer (Output Neuron)\n",
    "output = Dense(1, activation='linear')(dense) \n",
    "\n",
    "#tie together\n",
    "model = Model(inputs=inp, outputs=output)\n",
    "########################################################################\n",
    "\n",
    "\n",
    "#define optimizer\n",
    "optimizer = Adam(learning_rate=1E-3, epsilon=1E-3, clipnorm=True)\n",
    "  \n",
    "#compile the model\n",
    "model.compile(loss='mse', optimizer=optimizer, metrics=['mse'])\n",
    "\n",
    "#define early stopping callback\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=0, patience=20, restore_best_weights = True)\n",
    "\n",
    "#train the model\n",
    "history = model.fit(X_train, Y_train,validation_data=(X_stop, Y_stop), epochs=100, verbose=3,\n",
    "                    batch_size=32, callbacks=[es])\n",
    "\n",
    "#plot training loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.legend(['training loss','validation loss'])\n",
    "plt.title('Loss')\n",
    "plt.show()\n",
    "\n",
    "###################################\n",
    "#simulate testset\n",
    "sim = model.predict(X_test)\n",
    "\n",
    "#rescale simulated and observed values\n",
    "sim = scaler_gwl.inverse_transform(sim)  # retransform to original scale\n",
    "obs = scaler_gwl.inverse_transform(Y_test.reshape(-1,1))\n",
    "\n",
    "###################################\n",
    "\n",
    "\n",
    "#Nash-Sutcliffe-Efficiency: NSE\n",
    "NSE = 1 - ((np.sum((sim-obs) ** 2)) / (np.sum((obs - np.mean(obs)) ** 2)))\n",
    "#Root Mean Squared Error\n",
    "RMSE =  np.sqrt(np.mean((sim-obs) ** 2))\n",
    "#Pearson r\n",
    "r = stats.pearsonr(sim[:,0], obs[:,0])\n",
    "r = r[0] #r\n",
    "#Bias\n",
    "Bias = np.mean(sim-obs)\n",
    "scores = pd.DataFrame(np.array([[NSE, RMSE, r, Bias]]),\n",
    "                      columns=['NSE','RMSE','r','Bias'])\n",
    "print(scores)\n",
    "\n",
    "####################################\n",
    "\n",
    "## plot Test data and simulation\n",
    "plt.figure(figsize=(13,3))\n",
    "plt.plot(TestData.index, sim, 'r', label =\"simulated\", linewidth = 1.7)\n",
    "plt.plot(TestData.index, obs, 'k', label =\"observed\", linewidth=1.7,alpha=0.9)\n",
    "\n",
    "plt.title(\"Simulation of TestData\", size=17,fontweight = 'bold')\n",
    "plt.ylabel('GWL [m asl]', size=15)\n",
    "plt.xlabel('Date',size=15)\n",
    "plt.legend(fontsize=15,bbox_to_anchor=(1.2, 1),loc='upper right',fancybox = False, framealpha = 1, edgecolor = 'k')\n",
    "plt.tight_layout()\n",
    "plt.grid(visible=True, which='major', color='#666666', alpha = 0.3, linestyle='-')\n",
    "plt.xticks(fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {
    "e3303afb-972e-406f-9c77-0f0d2dab4404.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "b22f4dea",
   "metadata": {},
   "source": [
    "### Aufgabe 3: Regularisierungstechniken - robuste Modelle\n",
    "\n",
    "Füge zu dem Modell aus Aufgabe 1 ODER 2 einen BatchNorm Layer und einen Dropout Layer hinzu. Experimentiere mit der Dropout Rate. Welchen Effekt haben die Layer einzeln und gleichzeitig?\n",
    "\n",
    "**Hinweis**  \n",
    "Orientiere dich bei der Platzierung fürs erste an dieser Struktur:\n",
    "\n",
    "![image.png](attachment:e3303afb-972e-406f-9c77-0f0d2dab4404.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4563a36e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set seed\n",
    "seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "################################################################### 1D CNN Modell from above\n",
    "#Input Layer\n",
    "inp = Input(shape=(seq_length, X_train.shape[2]))\n",
    "\n",
    "# #1D-Conv Layer\n",
    "cnn = Conv1D(filters=256, kernel_size=3, activation='relu', padding='same')(inp)\n",
    "\n",
    "#Pooling Layer\n",
    "cnn = MaxPooling1D(padding='same')(cnn) \n",
    "\n",
    "#Flatten Layer\n",
    "cnn = Flatten()(cnn) \n",
    "\n",
    "#Dense layer\n",
    "dense = Dense(30, activation='relu')(cnn)\n",
    "\n",
    "#Output Layer (Output Neuron)\n",
    "output = Dense(1, activation='linear')(dense) \n",
    "\n",
    "#tie together\n",
    "model = Model(inputs=inp, outputs=output)\n",
    "########################################################################\n",
    "\n",
    "#define optimizer\n",
    "optimizer = Adam(learning_rate=1E-3, epsilon=1E-3, clipnorm=True)\n",
    "  \n",
    "#compile the model\n",
    "model.compile(loss='mse', optimizer=optimizer, metrics=['mse'])\n",
    "\n",
    "#define early stopping callback\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=0, patience=20, restore_best_weights = True)\n",
    "\n",
    "#train the model\n",
    "history = model.fit(X_train, Y_train,validation_data=(X_stop, Y_stop), epochs=100, verbose=3,\n",
    "                    batch_size=32, callbacks=[es])\n",
    "\n",
    "#plot training loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.legend(['training loss','validation loss'])\n",
    "plt.title('Loss')\n",
    "plt.show()\n",
    "\n",
    "###################################\n",
    "#simulate testset\n",
    "sim = model.predict(X_test)\n",
    "\n",
    "#rescale simulated and observed values\n",
    "sim = scaler_gwl.inverse_transform(sim)  # retransform to original scale\n",
    "obs = scaler_gwl.inverse_transform(Y_test.reshape(-1,1))\n",
    "###################################\n",
    "\n",
    "#Nash-Sutcliffe-Efficiency: NSE\n",
    "NSE = 1 - ((np.sum((sim-obs) ** 2)) / (np.sum((obs - np.mean(obs)) ** 2)))\n",
    "\n",
    "#Root Mean Squared Error\n",
    "RMSE =  np.sqrt(np.mean((sim-obs) ** 2))\n",
    "\n",
    "#Pearson r\n",
    "r = stats.pearsonr(sim[:,0], obs[:,0])\n",
    "r = r[0] #r\n",
    "\n",
    "#Bias\n",
    "Bias = np.mean(sim-obs)\n",
    "\n",
    "scores = pd.DataFrame(np.array([[NSE, RMSE, r, Bias]]),\n",
    "                      columns=['NSE','RMSE','r','Bias'])\n",
    "print(scores)\n",
    "\n",
    "#plot Test data and simulation\n",
    "plt.figure(figsize=(13,3))\n",
    "plt.plot(TestData.index, sim, 'r', label =\"simulated\", linewidth = 1.7)\n",
    "plt.plot(TestData.index, obs, 'k', label =\"observed\", linewidth=1.7,alpha=0.9)\n",
    "\n",
    "plt.title(\"Simulation of TestData\", size=17,fontweight = 'bold')\n",
    "plt.ylabel('GWL [m asl]', size=15)\n",
    "plt.xlabel('Date',size=15)\n",
    "plt.legend(fontsize=15,bbox_to_anchor=(1.2, 1),loc='upper right',fancybox = False, framealpha = 1, edgecolor = 'k')\n",
    "plt.tight_layout()\n",
    "plt.grid(visible=True, which='major', color='#666666', alpha = 0.3, linestyle='-')\n",
    "plt.xticks(fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53e491e7",
   "metadata": {},
   "source": [
    "Ihr könnt das natürlich auch mit einem LSTM statt einem CNN machen. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
